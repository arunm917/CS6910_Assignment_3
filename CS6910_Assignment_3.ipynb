{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LP7BX91WRUeS"
      ],
      "authorship_tag": "ABX9TyNsofqPCGmzj1vR+7eRWypg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arunm917/CS6910_Assignment_3/blob/main/CS6910_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading necessary packages and files"
      ],
      "metadata": {
        "id": "uixetIxwm_qE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gkx75o8qZtGB"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Jkkc0LcC4whY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading file from gdrive\n",
        "output = 'tam_train'\n",
        "file_id = '1pdJVD8P71fpqGRnvFfOp_6TbVft9NlnH' # Google drive ID\n",
        "#Download the file\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, quiet=False)\n",
        "print('DONE.')"
      ],
      "metadata": {
        "id": "bHm92AkybYZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fb5d51-11df-438d-d81e-2b89732dab6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pdJVD8P71fpqGRnvFfOp_6TbVft9NlnH\n",
            "To: /content/tam_train\n",
            "100%|██████████| 2.69M/2.69M [00:00<00:00, 17.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading file from gdrive\n",
        "output = 'tam_valid'\n",
        "file_id = '1pdp6ojHltRRNLXsmoQbGRc2Qn8X1EUJV' # Google drive ID\n",
        "#Download the file\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, quiet=False)\n",
        "print('DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AVeCbeNnQuw",
        "outputId": "c2259069-31cd-4914-f201-32d25b769174"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pdp6ojHltRRNLXsmoQbGRc2Qn8X1EUJV\n",
            "To: /content/tam_valid\n",
            "100%|██████████| 164k/164k [00:00<00:00, 44.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading file from gdrive\n",
        "output = 'tam_test'\n",
        "file_id = '1pdaTq-g2ZKhRKv6fRrSbEsJkOH5gdrEQ' # Google drive ID\n",
        "#Download the file\n",
        "gdown.download('https://drive.google.com/uc?id=' + file_id, output, quiet=False)\n",
        "print('DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgydhFEdnUZI",
        "outputId": "a819ef34-03f0-4c6b-f267-d9c4c91af012"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pdaTq-g2ZKhRKv6fRrSbEsJkOH5gdrEQ\n",
            "To: /content/tam_test\n",
            "100%|██████████| 157k/157k [00:00<00:00, 27.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "JEItPR0Hp904"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df = pd.read_csv('tam_train')\n",
        "valid_data_df = pd.read_csv('tam_valid')\n",
        "test_data_df = pd.read_csv('tam_test')"
      ],
      "metadata": {
        "id": "yKNN0xMhaI4L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_df.columns = ['English','Tamil']\n",
        "# valid_data_df.columns = ['English','Tamil']\n",
        "# test_data_df.columns = ['English','Tamil']"
      ],
      "metadata": {
        "id": "wiKR6-yZ4pKX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating vocabulary"
      ],
      "metadata": {
        "id": "L6B8VQgLq0Na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating vocabulary\n",
        "\n",
        "char_list = []\n",
        "for i in range(len(train_data_df['English'])):\n",
        "  char = [*train_data_df.loc[i, 'English']]\n",
        "  char_list.extend(char)\n",
        "\n",
        "for i in range(len(train_data_df['Tamil'])):\n",
        "  char = [*train_data_df.loc[i, 'Tamil']]\n",
        "  char_list.extend(char)\n",
        "# vocabulary = set(vocabulary)\n",
        "print(len(char_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRuAnljKTPk9",
        "outputId": "96e71bc8-98e7-43e7-9bca-5cbd835336d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1343101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing\n",
        "\n",
        "SOS_token = '<SOS>'\n",
        "EOS_token = '<EOS>'\n",
        "PAD_token = '<PAD>'\n",
        "UNK_token = '<UNK>'\n",
        "\n",
        "vocabulary = list(set(char_list))\n",
        "vocabulary = [PAD_token] + [UNK_token] + vocabulary + [SOS_token] + [EOS_token]"
      ],
      "metadata": {
        "id": "UB3ZXOTcZD5s"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocabulary))\n",
        "print(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dczXQkPcS0b",
        "outputId": "adc5991a-ffd5-4751-8856-46b4922edcd6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76\n",
            "['<PAD>', '<UNK>', 'உ', 'd', 'ஃ', 'ஐ', 'f', 'ழ', 'ச', 'எ', 'z', 'r', 'ஸ', 'ன', 'v', 'p', 'அ', 'ஊ', 'ற', 'ஈ', 'n', 'ீ', 'ௌ', 'ய', 'i', 'ு', 'இ', 'ா', '்', 'ப', 'ள', 'ோ', 'ண', 'ஹ', 'வ', 'ஞ', 'ல', 'g', 'ஒ', 'j', 'w', 'ங', 'ெ', 'h', 'ூ', 'ஏ', 'a', 'ஆ', 'ஜ', 'ை', 'y', 'ட', 'o', 'b', 'ஓ', 'q', 'க', 'ந', 'ே', 'ர', 'l', 'k', 'e', 'x', 'ொ', 't', 'm', 's', 'ஷ', 'த', 'c', 'ி', 'ம', 'u', '<SOS>', '<EOS>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_index = {value: index for index, value in enumerate(vocabulary)}\n",
        "num_list = [char_index[char] for char in vocabulary]\n",
        "print(char_index)\n",
        "print(num_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8vdEmMsbw6U",
        "outputId": "21f21657-a356-4f2a-ab2f-b249bc987131"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, '<UNK>': 1, 'உ': 2, 'd': 3, 'ஃ': 4, 'ஐ': 5, 'f': 6, 'ழ': 7, 'ச': 8, 'எ': 9, 'z': 10, 'r': 11, 'ஸ': 12, 'ன': 13, 'v': 14, 'p': 15, 'அ': 16, 'ஊ': 17, 'ற': 18, 'ஈ': 19, 'n': 20, 'ீ': 21, 'ௌ': 22, 'ய': 23, 'i': 24, 'ு': 25, 'இ': 26, 'ா': 27, '்': 28, 'ப': 29, 'ள': 30, 'ோ': 31, 'ண': 32, 'ஹ': 33, 'வ': 34, 'ஞ': 35, 'ல': 36, 'g': 37, 'ஒ': 38, 'j': 39, 'w': 40, 'ங': 41, 'ெ': 42, 'h': 43, 'ூ': 44, 'ஏ': 45, 'a': 46, 'ஆ': 47, 'ஜ': 48, 'ை': 49, 'y': 50, 'ட': 51, 'o': 52, 'b': 53, 'ஓ': 54, 'q': 55, 'க': 56, 'ந': 57, 'ே': 58, 'ர': 59, 'l': 60, 'k': 61, 'e': 62, 'x': 63, 'ொ': 64, 't': 65, 'm': 66, 's': 67, 'ஷ': 68, 'த': 69, 'c': 70, 'ி': 71, 'ம': 72, 'u': 73, '<SOS>': 74, '<EOS>': 75}\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tokenizer\n",
        "max_length = 10\n",
        "def tokenize(word):\n",
        "    # Convert the sentence to lowercase and split it into words\n",
        "    # print(word)\n",
        "    chars = [*word]\n",
        "\n",
        "    # print(chars)\n",
        "    # chars = chars + ['<EOS>'] + ['<PAD>'] * (max_length - len(chars) - 1)\n",
        "    # Map each word to its index in the vocabulary\n",
        "    tokens = [char_index[char] if char in char_index else 0 for char in chars]\n",
        "    \n",
        "    return tokens"
      ],
      "metadata": {
        "id": "DWrNfanAtOvi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the training pairs\n",
        "training_pairs = train_data_df.values.tolist()\n",
        "val_pairs = valid_data_df.values.tolist()\n",
        "test_pairs = test_data_df.values.tolist()"
      ],
      "metadata": {
        "id": "mDoAvRMB050I"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqzN_GspJCnT",
        "outputId": "fb0654c7-30d5-44d6-b891-2c7a658794ba"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4095"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the tokenize function\n",
        "tokenize('arun')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJDnvKfzrIaY",
        "outputId": "5546c252-3eb3-47dd-d575-178844f59841"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[46, 11, 73, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_words = [tokenize(pair[0]) for pair in training_pairs]\n",
        "tam_words = [tokenize(pair[1]) for pair in training_pairs]"
      ],
      "metadata": {
        "id": "BnKBJPS8BVdM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Determining max length\n",
        "max_length = max([len(words) for words in eng_words + tam_words])\n",
        "print(max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFD9A6kACNa9",
        "outputId": "5a0c5e7d-629b-4c33-c778-67b3b3112c4d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(word_pairs):\n",
        "  ''' Function to pad the input and target sequences. Padding is done to ensure that\n",
        "      all the training, validation and test samples are of equal size.'''\n",
        "\n",
        "  eng_words = [tokenize(pair[0]) for pair in word_pairs]\n",
        "  tam_words = [tokenize(pair[1]) for pair in word_pairs]\n",
        "  padded_input_sequences = [torch.tensor(words + [char_index['<EOS>']] + [(char_index['<PAD>'])]*(max_length - len(words))) for words in eng_words]\n",
        "  padded_target_sequences = [torch.tensor(words + [char_index['<EOS>']] + [(char_index['<PAD>'])]*(max_length - len(words))) for words in tam_words]\n",
        "  tensor = torch.tensor([char_index['<PAD>']]*(max_length+1))\n",
        "  padded_input_sequences.append(tensor)\n",
        "  padded_target_sequences.append(tensor)\n",
        "  padded_input_sequences = torch.stack(padded_input_sequences)\n",
        "  padded_target_sequences = torch.stack(padded_target_sequences)\n",
        "  \n",
        "  return(padded_input_sequences,padded_target_sequences)\n"
      ],
      "metadata": {
        "id": "6jJPAiIbL_cE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating datasets\n",
        "training_input_sequences, training_target_sequences = padding(training_pairs)\n",
        "train_dataset = torch.utils.data.TensorDataset(training_input_sequences, training_target_sequences)\n",
        "\n",
        "val_input_sequences, val_target_sequences = padding(val_pairs)\n",
        "val_dataset = torch.utils.data.TensorDataset(val_input_sequences, val_target_sequences)\n",
        "\n",
        "test_input_sequences, test_target_sequences = padding(test_pairs)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_input_sequences, test_target_sequences)"
      ],
      "metadata": {
        "id": "1mLjEjNevW_4"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture"
      ],
      "metadata": {
        "id": "zNOalLjTgryp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the EncoderRNN model\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, cell_type):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, num_layers)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, -1, self.hidden_size)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        return output, hidden\n",
        "    \n",
        "    def initHidden(self, batch_size):\n",
        "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)"
      ],
      "metadata": {
        "id": "gsqDMAwQxXLq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the DecoderRNN model\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, num_layers, cell_type):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, num_layers)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output = self.softmax(self.out(output))\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "SE4suGyTzO76"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(encoder, decoder, val_loader, device):\n",
        "    ''' This function calculates word-level accuracy which is used as the\n",
        "        evaluation metric.'''\n",
        "    encoder.eval()\n",
        "    decoder.eval()\n",
        "\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_seq, target_seq in val_loader:\n",
        "            batch_size = input_seq.size(0)\n",
        "\n",
        "            # Initializing the encoder and decoder hidden states\n",
        "            encoder_hidden = encoder.initHidden(batch_size)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            # Forward pass through the encoder\n",
        "            input_length = input_seq.size(1)\n",
        "            for i in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(input_seq[:, i], encoder_hidden)\n",
        "\n",
        "            # Initialize the decoder input to the start token\n",
        "            decoder_input = torch.tensor([[74] * batch_size]).to(device)\n",
        "\n",
        "            # Forward pass through the decoder\n",
        "            target_length = target_seq.size(1)\n",
        "            decoded_words = []\n",
        "            for i in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                topv, topi = decoder_output.data.topk(1)\n",
        "                decoded_words.append(topi.view(-1).tolist())\n",
        "\n",
        "                # Setting decoder input to the current target token\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "            # Calculating the word-level accuracy\n",
        "            for i in range(batch_size):\n",
        "                target_words = [val_loader.dataset.idx2word[idx] for idx in target_seq[i].tolist()]\n",
        "                decoded_words_i = [val_loader.dataset.idx2word[idx] for idx in decoded_words[i]]\n",
        "                correct = sum([1 if target_words[j] == decoded_words_i[j] else 0 for j in range(len(target_words))])\n",
        "                total_correct += correct\n",
        "                total_words += len(target_words)\n",
        "\n",
        "    return total_correct / total_words"
      ],
      "metadata": {
        "id": "7Fpv14RjBTAp"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "LP7BX91WRUeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining hyperparameters\n",
        "input_size = len(vocabulary)  # size of the vocabulary\n",
        "output_size = len(vocabulary)\n",
        "hidden_size = 256\n",
        "learning_rate = 0.01\n",
        "num_layers = 2\n",
        "cell_type = 'RNN'\n",
        "num_epochs = 2\n",
        "batch_size = 128\n",
        "\n",
        "# Defining EncoderRNN model and optimizer\n",
        "encoder = EncoderRNN(input_size, hidden_size, num_layers, cell_type)\n",
        "decoder = DecoderRNN(hidden_size, output_size, num_layers, cell_type)"
      ],
      "metadata": {
        "id": "VshMHcHWyoa5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "4In6N1XzgpJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "_JaFVJCnIY3V"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the loss function and the optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)"
      ],
      "metadata": {
        "id": "5My5bshgzd8B"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "'''In this part of the code the encoder-decoder model is trained.\n",
        "   The input sequence is given to the encoder which outputs an encoded\n",
        "   represenatation and a hidden state. The output of the encoder (context vector)\n",
        "   is then fed to the decoder to be decoded'''\n",
        "   \n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    loss = 0\n",
        "    for batch_idx, (input_seq, target_seq) in enumerate(train_loader):\n",
        "        # Zero gradients and reset the hidden states\n",
        "        optimizer.zero_grad()\n",
        "        encoder_hidden = encoder.initHidden(input_seq.size(0))\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # print('\\nbatch:', batch_idx, '\\ninput:', input_seq, '\\ntarget:', target_seq)\n",
        "\n",
        "        # Forward pass through the encoder\n",
        "        input_length = input_seq.size(1)\n",
        "        # print('input length:',input_length)\n",
        "        \n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_seq[:, i], encoder_hidden)\n",
        "        # print('encoder output', encoder_output.shape)\n",
        "        # print('encoder hidden', encoder_hidden.shape)\n",
        "\n",
        "        # Initialize the decoder input to the start token\n",
        "        decoder_input = torch.tensor([[74] * batch_size])\n",
        "        # print('decoder_input:', decoder_input.shape)\n",
        "        # print(decoder_input)\n",
        "\n",
        "        # Forward pass through the decoder\n",
        "        target_length = target_seq.size(1)\n",
        "        for i in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss = criterion(decoder_output.squeeze(), target_seq[:, i])\n",
        "            loss += loss.item()\n",
        "\n",
        "            # Setting decoder input to the current target token\n",
        "            decoder_input = target_seq[:, i].unsqueeze(0)\n",
        "\n",
        "        # Backward pass and optimizer step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    val_accuracy = accuracy(encoder, decoder, val_loader, device)\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Val Accuracy: {:.4f}'.format(epoch+1, num_epochs, loss, val_accuracy))\n"
      ],
      "metadata": {
        "id": "SOC7mG2Ayv2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}